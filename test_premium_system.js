const { GoogleGenerativeAI } = require('@google/generative-ai');

// Configurar Gemini para testing
const genAI = new GoogleGenerativeAI(process.env.GOOGLE_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

async function testPremiumSystem() {
  console.log('üß™ Testing Sistema Premium con Gemini...\n');
  
  try {
    // Test 1: Detecci√≥n de idioma y sentimiento
    console.log('1Ô∏è‚É£ Testing detecci√≥n de idioma y sentimiento...');
    await testLanguageDetection();
    
    // Test 2: Generaci√≥n de respuestas
    console.log('\n2Ô∏è‚É£ Testing generaci√≥n de respuestas...');
    await testResponseGeneration();
    
    // Test 3: Extracci√≥n de informaci√≥n
    console.log('\n3Ô∏è‚É£ Testing extracci√≥n de informaci√≥n...');
    await testInformationExtraction();
    
    // Test 4: An√°lisis de conversaci√≥n
    console.log('\n4Ô∏è‚É£ Testing an√°lisis de conversaci√≥n...');
    await testConversationAnalysis();
    
    console.log('\n‚úÖ Todos los tests completados exitosamente!');
    
  } catch (error) {
    console.error('‚ùå Error en testing:', error);
  }
}

async function testLanguageDetection() {
  const testCases = [
    { input: "Hola, quiero hacer una reserva", expected: "es" },
    { input: "Hello, I would like to make a reservation", expected: "en" },
    { input: "Hallo, ich m√∂chte eine Reservierung machen", expected: "de" },
    { input: "Ciao, vorrei fare una prenotazione", expected: "it" },
    { input: "Bonjour, je voudrais faire une r√©servation", expected: "fr" },
    { input: "Ol√°, gostaria de fazer uma reserva", expected: "pt" }
  ];
  
  for (const testCase of testCases) {
    try {
      const prompt = `
      Analiza este input del usuario: "${testCase.input}"
      
      Responde en JSON con:
      {
        "language": "c√≥digo del idioma (es, en, de, it, fr, pt)",
        "sentiment": "positive/neutral/negative/frustrated",
        "intent": "reservation/information/cancellation/other",
        "urgency": "low/medium/high",
        "confidence": 0.0-1.0
      }
      `;
      
      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();
      
      const analysis = JSON.parse(text);
      console.log(`   Input: "${testCase.input}"`);
      console.log(`   Detected: ${analysis.language} (expected: ${testCase.expected})`);
      console.log(`   Sentiment: ${analysis.sentiment}, Confidence: ${analysis.confidence}`);
      console.log(`   ‚úÖ ${analysis.language === testCase.expected ? 'CORRECT' : 'INCORRECT'}\n`);
      
    } catch (error) {
      console.log(`   ‚ùå Error testing "${testCase.input}": ${error.message}\n`);
    }
  }
}

async function testResponseGeneration() {
  const testCases = [
    { step: 'greeting', language: 'es', sentiment: 'positive' },
    { step: 'greeting', language: 'en', sentiment: 'frustrated' },
    { step: 'ask_people', language: 'de', sentiment: 'neutral' },
    { step: 'ask_date', language: 'it', sentiment: 'positive' },
    { step: 'complete', language: 'fr', sentiment: 'positive' }
  ];
  
  for (const testCase of testCases) {
    try {
      const prompt = `
      Eres un recepcionista premium de restaurante en ${testCase.language}.
      Sentimiento del cliente: ${testCase.sentiment}
      Paso: ${testCase.step}
      
      Genera una respuesta natural y profesional. M√°ximo 15 palabras.
      `;
      
      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();
      
      console.log(`   Step: ${testCase.step}, Language: ${testCase.language}, Sentiment: ${testCase.sentiment}`);
      console.log(`   Response: "${text.trim()}"`);
      console.log(`   ‚úÖ Generated successfully\n`);
      
    } catch (error) {
      console.log(`   ‚ùå Error generating response: ${error.message}\n`);
    }
  }
}

async function testInformationExtraction() {
  const testCases = [
    { type: 'people', input: "Para 4 personas", expected: 4 },
    { type: 'people', input: "We need a table for 6 people", expected: 6 },
    { type: 'date', input: "Para ma√±ana", expected: "date" },
    { type: 'date', input: "Next Friday", expected: "date" },
    { type: 'time', input: "A las 8 de la noche", expected: "20:00" },
    { type: 'time', input: "At 7:30 PM", expected: "19:30" },
    { type: 'name', input: "Mi nombre es Juan", expected: "Juan" },
    { type: 'name', input: "I'm called Maria", expected: "Maria" }
  ];
  
  for (const testCase of testCases) {
    try {
      const prompt = `
      Extrae la informaci√≥n de tipo "${testCase.type}" de este texto: "${testCase.input}"
      
      Responde en JSON:
      {
        "${testCase.type}": valor_extra√≠do,
        "confidence": 0.0-1.0
      }
      `;
      
      const result = await model.generateContent(prompt);
      const response = await result.response;
      const text = response.text();
      
      const extraction = JSON.parse(text);
      console.log(`   Type: ${testCase.type}, Input: "${testCase.input}"`);
      console.log(`   Extracted: ${JSON.stringify(extraction[testCase.type])} (expected: ${testCase.expected})`);
      console.log(`   Confidence: ${extraction.confidence}`);
      console.log(`   ‚úÖ Extracted successfully\n`);
      
    } catch (error) {
      console.log(`   ‚ùå Error extracting ${testCase.type}: ${error.message}\n`);
    }
  }
}

async function testConversationAnalysis() {
  const mockConversation = [
    { role: 'user', message: 'Hola, quiero hacer una reserva' },
    { role: 'bot', message: '¬°Hola! Bienvenido. ¬øPara cu√°ntas personas?' },
    { role: 'user', message: 'Para 4 personas' },
    { role: 'bot', message: 'Perfecto. ¬øPara qu√© fecha?' },
    { role: 'user', message: 'Para ma√±ana' },
    { role: 'bot', message: 'Excelente. ¬øA qu√© hora?' },
    { role: 'user', message: 'A las 8' },
    { role: 'bot', message: 'Muy bien. ¬øSu nombre?' },
    { role: 'user', message: 'Juan' },
    { role: 'bot', message: 'Perfecto Juan. ¬øUsa este n√∫mero o prefiere otro?' },
    { role: 'user', message: 'Este mismo' },
    { role: 'bot', message: 'Confirmo: 4 personas, ma√±ana a las 8, Juan. ¬øEs correcto?' },
    { role: 'user', message: 'S√≠, perfecto' },
    { role: 'bot', message: '¬°Excelente! Reserva confirmada. ¬°Hasta ma√±ana!' }
  ];
  
  try {
    const prompt = `
    Analiza esta conversaci√≥n de reserva:
    
    ${JSON.stringify(mockConversation, null, 2)}
    
    Genera un an√°lisis completo que incluya:
    1. Resumen ejecutivo
    2. An√°lisis de sentimiento del cliente
    3. Efectividad de las respuestas del bot
    4. Sugerencias de mejora espec√≠ficas
    5. Puntuaci√≥n de calidad (0-100)
    6. Recomendaciones para futuras conversaciones
    
    Formato: Markdown estructurado y profesional.
    `;
    
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    console.log('   üìä An√°lisis de conversaci√≥n generado:');
    console.log('   ' + text.substring(0, 200) + '...');
    console.log('   ‚úÖ Analysis completed successfully\n');
    
  } catch (error) {
    console.log(`   ‚ùå Error analyzing conversation: ${error.message}\n`);
  }
}

// Ejecutar tests
testPremiumSystem();
